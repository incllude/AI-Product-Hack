"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å YandexGPT API –¥–ª—è LangGraph
–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å YandexCloudML SDK –∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
"""
import json
import requests
from typing import Any, Dict, List, Optional, AsyncIterator
from langchain_core.language_models.llms import LLM
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.callbacks.manager import CallbackManagerForLLMRun, AsyncCallbackManagerForLLMRun
from langchain_core.outputs import ChatGeneration, ChatResult, LLMResult, Generation
from pydantic import Field
import os
from dotenv import load_dotenv
import asyncio
import aiohttp
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç YandexCloudML SDK
try:
    from yandex_cloud_ml_sdk import YCloudML
    YANDEX_SDK_AVAILABLE = True
except ImportError:
    YANDEX_SDK_AVAILABLE = False
    print("Warning: yandex_cloud_ml_sdk –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∫ HTTP API")

load_dotenv()


class YandexGPT(LLM):
    """–ö–∞—Å—Ç–æ–º–Ω–∞—è LLM –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YandexGPT API —á–µ—Ä–µ–∑ YandexCloudML SDK —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏"""
    
    api_key: str = Field(default_factory=lambda: os.getenv("YANDEX_API_KEY", ""))
    folder_id: str = Field(default_factory=lambda: os.getenv("YANDEX_FOLDER_ID", ""))
    model_id: str = Field(default_factory=lambda: os.getenv("YANDEX_MODEL_ID", "yandexgpt"))
    temperature: float = Field(default=0.7)
    max_tokens: int = Field(default=2000)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è LangGraph
    request_count: int = Field(default=0)
    total_tokens: int = Field(default=0)
    last_request_time: Optional[datetime] = Field(default=None)
    
    # YandexCloudML SDK –æ–±—ä–µ–∫—Ç (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –ª–µ–Ω–∏–≤–æ)
    sdk: Optional[Any] = Field(default=None, exclude=True)
    
    @property
    def _llm_type(self) -> str:
        return "yandex_gpt_sdk" if YANDEX_SDK_AVAILABLE else "yandex_gpt_http"
    
    def _get_sdk(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä YandexCloudML SDK"""
        if not YANDEX_SDK_AVAILABLE:
            raise RuntimeError("YandexCloudML SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
        if self.sdk is None:
            self.sdk = YCloudML(
                folder_id=self.folder_id,
                auth=self.api_key,
            )
        return self.sdk
    
    def _call_with_sdk(self, prompt: str, **kwargs) -> str:
        """–í—ã–∑–æ–≤ —á–µ—Ä–µ–∑ YandexCloudML SDK —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –æ–∂–∏–¥–∞–Ω–∏–µ–º"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º SDK
            sdk = self._get_sdk()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ kwargs
            temperature = kwargs.get('temperature', self.temperature)
            max_tokens = kwargs.get('max_tokens', self.max_tokens)
            
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model = sdk.models.completions(self.model_id)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ YandexCloudML
            messages = [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–ø–µ—Ä–∞—Ü–∏—é —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            operation = model.configure(
                temperature=temperature,
                max_tokens=max_tokens
            ).run_deferred(messages)
            
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—è wait() - –∫–∞–∫ –≤–æ –≤—Ç–æ—Ä–æ–º –≤–∞—Ä–∏–∞–Ω—Ç–µ –∏–∑ async_variant.py
            result = operation.wait()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞: GPTModelResult(alternatives=(Alternative(text='...'),), ...)
            if hasattr(result, 'alternatives') and result.alternatives:
                # –í –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ: result.alternatives[0].text (–Ω–µ .message.text)
                text_result = result.alternatives[0].text
            elif hasattr(result, 'text'):
                text_result = result.text
            else:
                text_result = str(result)
            
            return text_result
            
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ YandexCloudML SDK: {str(e)}")
    
    def _call_with_http(self, prompt: str, **kwargs) -> str:
        """Fallback –∫ HTTP API –µ—Å–ª–∏ SDK –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        print("üîç [YandexGPT HTTP] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ HTTP –∑–∞–ø—Ä–æ—Å–∞ –∫ API...")
        
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Api-Key {self.api_key}"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ kwargs
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        payload = {
            "modelUri": f"gpt://{self.folder_id}/{self.model_id}",
            "completionOptions": {
                "stream": False,
                "temperature": temperature,
                "maxTokens": str(max_tokens)
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }
        
        print(f"üîç [YandexGPT HTTP] URL: {url}")
        print(f"üîç [YandexGPT HTTP] ModelUri: gpt://{self.folder_id}/{self.model_id}")
        print(f"üîç [YandexGPT HTTP] Temperature: {temperature}, MaxTokens: {max_tokens}")
        print("üîç [YandexGPT HTTP] –û—Ç–ø—Ä–∞–≤–∫–∞ POST –∑–∞–ø—Ä–æ—Å–∞...")
        
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        print(f"üîç [YandexGPT HTTP] –ü–æ–ª—É—á–µ–Ω —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
        
        response.raise_for_status()
        
        result = response.json()
        text_result = result["result"]["alternatives"][0]["message"]["text"]
        print(f"‚úÖ [YandexGPT HTTP] –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–æ–π {len(text_result)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return text_result
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """–í—ã–∑–æ–≤ YandexGPT API"""
        
        print(f"üîç [YandexGPT] –ù–∞—á–∞–ª–æ API –≤—ã–∑–æ–≤–∞ (–∑–∞–ø—Ä–æ—Å #{self.request_count + 1})")
        print(f"üîç [YandexGPT] –î–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üîç [YandexGPT] –ü—Ä–æ–º–ø—Ç: {prompt[:200]}...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º credentials –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º
            if not self.api_key:
                raise ValueError("API –∫–ª—é—á Yandex –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            if not self.folder_id:
                raise ValueError("Folder ID Yandex –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.request_count += 1
            self.last_request_time = datetime.now()
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SDK, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if YANDEX_SDK_AVAILABLE:
                print("üîç [YandexGPT] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ YandexCloudML SDK...")
                text_result = self._call_with_sdk(prompt, **kwargs)
            else:
                print("üîç [YandexGPT] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ HTTP API fallback...")
                text_result = self._call_with_http(prompt, **kwargs)
            
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
            estimated_tokens = len(text_result.split()) * 1.3
            self.total_tokens += int(estimated_tokens)
            
            print(f"‚úÖ [YandexGPT] API –≤—ã–∑–æ–≤ —É—Å–ø–µ—à–µ–Ω. –ü–æ–ª—É—á–µ–Ω–æ {len(text_result)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"‚úÖ [YandexGPT] –û—Ç–≤–µ—Ç: {text_result[:200]}...")
            
            return text_result
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ YandexGPT: {str(e)}"
            print(f"‚ùå [YandexGPT] {error_msg}")
            if run_manager:
                run_manager.on_llm_error(Exception(error_msg))
            return error_msg
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            'request_count': self.request_count,
            'total_tokens': self.total_tokens,
            'last_request_time': self.last_request_time.isoformat() if self.last_request_time else None,
            'model_id': self.model_id,
            'temperature': self.temperature,
            'max_tokens': self.max_tokens,
            'sdk_available': YANDEX_SDK_AVAILABLE,
            'sdk_type': 'yandex_cloud_ml_sdk' if YANDEX_SDK_AVAILABLE else 'http_api'
        }
    
    def reset_stats(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        self.request_count = 0
        self.total_tokens = 0
        self.last_request_time = None


class YandexGPTChat(BaseChatModel):
    """–ß–∞—Ç-–º–æ–¥–µ–ª—å –¥–ª—è YandexGPT —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–æ–æ–±—â–µ–Ω–∏–π"""
    
    api_key: str = Field(default_factory=lambda: os.getenv("YANDEX_API_KEY", ""))
    folder_id: str = Field(default_factory=lambda: os.getenv("YANDEX_FOLDER_ID", ""))
    model_id: str = Field(default_factory=lambda: os.getenv("YANDEX_MODEL_ID", "yandexgpt-lite"))
    temperature: float = Field(default=0.7)
    max_tokens: int = Field(default=2000)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è LangGraph
    request_count: int = Field(default=0)
    total_tokens: int = Field(default=0)
    last_request_time: Optional[datetime] = Field(default=None)
    
    @property
    def _llm_type(self) -> str:
        return "yandex_gpt_chat"
    
    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> ChatResult:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç YandexGPT
        yandex_messages = self._convert_messages_to_yandex_format(messages)
        
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Api-Key {self.api_key}"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ kwargs
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        payload = {
            "modelUri": f"gpt://{self.folder_id}/{self.model_id}",
            "completionOptions": {
                "stream": False,
                "temperature": temperature,
                "maxTokens": str(max_tokens)
            },
            "messages": yandex_messages
        }
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.request_count += 1
            self.last_request_time = datetime.now()
            
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            text_result = result["result"]["alternatives"][0]["message"]["text"]
            
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
            estimated_tokens = len(text_result.split()) * 1.3
            self.total_tokens += int(estimated_tokens)
            
            # –°–æ–∑–¥–∞–µ–º ChatGeneration
            message = AIMessage(content=text_result)
            generation = ChatGeneration(message=message)
            
            return ChatResult(generations=[generation])
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –≤ YandexGPT Chat: {str(e)}"
            if run_manager:
                run_manager.on_llm_error(Exception(error_msg))
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –∫–∞–∫ —Å–æ–æ–±—â–µ–Ω–∏–µ
            error_message = AIMessage(content=error_msg)
            error_generation = ChatGeneration(message=error_message)
            return ChatResult(generations=[error_generation])
    
    def _convert_messages_to_yandex_format(self, messages: List[BaseMessage]) -> List[Dict[str, str]]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è LangChain –≤ —Ñ–æ—Ä–º–∞—Ç YandexGPT"""
        yandex_messages = []
        
        for message in messages:
            if isinstance(message, SystemMessage):
                # YandexGPT –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é,
                # –ø–æ—ç—Ç–æ–º—É –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
                yandex_messages.append({
                    "role": "user",
                    "text": f"–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {message.content}"
                })
            elif isinstance(message, HumanMessage):
                yandex_messages.append({
                    "role": "user",
                    "text": message.content
                })
            elif isinstance(message, AIMessage):
                yandex_messages.append({
                    "role": "assistant",
                    "text": message.content
                })
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é —Ä–æ–ª—å
                yandex_messages.append({
                    "role": "user",
                    "text": str(message.content)
                })
        
        return yandex_messages
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            'request_count': self.request_count,
            'total_tokens': self.total_tokens,
            'last_request_time': self.last_request_time.isoformat() if self.last_request_time else None,
            'model_id': self.model_id,
            'temperature': self.temperature,
            'max_tokens': self.max_tokens
        }
    
    def reset_stats(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        self.request_count = 0
        self.total_tokens = 0
        self.last_request_time = None


class AsyncYandexGPT:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è YandexGPT –¥–ª—è LangGraph"""
    
    def __init__(
        self,
        api_key: str = None,
        folder_id: str = None,
        model_id: str = None,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ):
        self.api_key = api_key or os.getenv("YANDEX_API_KEY", "")
        self.folder_id = folder_id or os.getenv("YANDEX_FOLDER_ID", "")
        self.model_id = model_id or os.getenv("YANDEX_MODEL_ID", "yandexgpt-lite")
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.request_count = 0
        self.total_tokens = 0
        self.last_request_time = None
    
    async def agenerate(self, prompt: str, **kwargs) -> str:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Api-Key {self.api_key}"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ kwargs
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        payload = {
            "modelUri": f"gpt://{self.folder_id}/{self.model_id}",
            "completionOptions": {
                "stream": False,
                "temperature": temperature,
                "maxTokens": str(max_tokens)
            },
            "messages": [
                {
                    "role": "user",
                    "text": prompt
                }
            ]
        }
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.request_count += 1
            self.last_request_time = datetime.now()
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url, 
                    headers=headers, 
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    response.raise_for_status()
                    result = await response.json()
            
            text_result = result["result"]["alternatives"][0]["message"]["text"]
            
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
            estimated_tokens = len(text_result.split()) * 1.3
            self.total_tokens += int(estimated_tokens)
            
            return text_result
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≤ AsyncYandexGPT: {str(e)}"
    
    async def achat(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ —á–∞—Ç-—Ä–µ–∂–∏–º–µ"""
        
        url = "https://llm.api.cloud.yandex.net/foundationModels/v1/completion"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Api-Key {self.api_key}"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ kwargs
        temperature = kwargs.get('temperature', self.temperature)
        max_tokens = kwargs.get('max_tokens', self.max_tokens)
        
        payload = {
            "modelUri": f"gpt://{self.folder_id}/{self.model_id}",
            "completionOptions": {
                "stream": False,
                "temperature": temperature,
                "maxTokens": str(max_tokens)
            },
            "messages": messages
        }
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.request_count += 1
            self.last_request_time = datetime.now()
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url, 
                    headers=headers, 
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    response.raise_for_status()
                    result = await response.json()
            
            text_result = result["result"]["alternatives"][0]["message"]["text"]
            
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
            estimated_tokens = len(text_result.split()) * 1.3
            self.total_tokens += int(estimated_tokens)
            
            return text_result
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≤ AsyncYandexGPT chat: {str(e)}"
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            'request_count': self.request_count,
            'total_tokens': self.total_tokens,
            'last_request_time': self.last_request_time.isoformat() if self.last_request_time else None,
            'model_id': self.model_id,
            'temperature': self.temperature,
            'max_tokens': self.max_tokens
        }
    
    def reset_stats(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        self.request_count = 0
        self.total_tokens = 0
        self.last_request_time = None


# –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ –¥–ª—è LangGraph

def create_yandex_llm(
    temperature: float = 0.7,
    max_tokens: int = 2000,
    model_id: str = None
) -> YandexGPT:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä YandexGPT LLM"""
    print("üîç [YandexGPT] –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ YandexGPT LLM...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    api_key = os.getenv("YANDEX_API_KEY", "")
    folder_id = os.getenv("YANDEX_FOLDER_ID", "")
    model = model_id or os.getenv("YANDEX_MODEL_ID", "yandexgpt")
    
    print(f"üîç [YandexGPT] API –∫–ª—é—á: {'‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if api_key else '‚ùå –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
    print(f"üîç [YandexGPT] Folder ID: {'‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if folder_id else '‚ùå –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}")
    print(f"üîç [YandexGPT] –ú–æ–¥–µ–ª—å: {model}")
    print(f"üîç [YandexGPT] SDK –¥–æ—Å—Ç—É–ø–µ–Ω: {'‚úÖ –¥–∞' if YANDEX_SDK_AVAILABLE else '‚ùå –Ω–µ—Ç'}")
    
    llm = YandexGPT(
        temperature=temperature,
        max_tokens=max_tokens,
        model_id=model
    )
    
    print("‚úÖ [YandexGPT] –≠–∫–∑–µ–º–ø–ª—è—Ä LLM —Å–æ–∑–¥–∞–Ω")
    return llm

def create_yandex_chat(
    temperature: float = 0.7,
    max_tokens: int = 2000,
    model_id: str = None
) -> YandexGPTChat:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä YandexGPT Chat"""
    return YandexGPTChat(
        temperature=temperature,
        max_tokens=max_tokens,
        model_id=model_id or os.getenv("YANDEX_MODEL_ID", "yandexgpt-lite")
    )

def create_async_yandex_llm(
    temperature: float = 0.7,
    max_tokens: int = 2000,
    model_id: str = None
) -> AsyncYandexGPT:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ YandexGPT"""
    return AsyncYandexGPT(
        temperature=temperature,
        max_tokens=max_tokens,
        model_id=model_id or os.getenv("YANDEX_MODEL_ID", "yandexgpt-lite")
    )

def validate_yandex_config() -> Dict[str, Any]:
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é YandexGPT"""
    config = {
        'api_key': bool(os.getenv("YANDEX_API_KEY")),
        'folder_id': bool(os.getenv("YANDEX_FOLDER_ID")),
        'model_id': os.getenv("YANDEX_MODEL_ID", "yandexgpt"),
        'sdk_available': YANDEX_SDK_AVAILABLE
    }
    
    config['is_valid'] = config['api_key'] and config['folder_id']
    
    if not config['is_valid']:
        missing = []
        if not config['api_key']:
            missing.append('YANDEX_API_KEY')
        if not config['folder_id']:
            missing.append('YANDEX_FOLDER_ID')
        config['missing_vars'] = missing
    
    return config